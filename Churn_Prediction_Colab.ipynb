{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d4d38c",
   "metadata": {},
   "source": [
    "# ðŸ“Œ Churn Prediction and Retention System\n",
    "This notebook implements a complete end-to-end pipeline for customer churn prediction and retention strategies using MySQL, Machine Learning, NLP, and Generative AI Chatbots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05048d9d",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 1: Connect to MySQL & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install necessary libraries\n",
    "!pip install mysql-connector-python sqlalchemy pandas\n",
    "\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connect to MySQL Database\n",
    "db_connection_str = \"mysql+mysqlconnector://<user>:<password>@<host>:<port>/<database>\"\n",
    "engine = create_engine(db_connection_str)\n",
    "\n",
    "# Load dataset from MySQL into Pandas DataFrame\n",
    "query = \"SELECT * FROM customer_churn_data;\"\n",
    "df = pd.read_sql(query, con=engine)\n",
    "\n",
    "# Display data structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b65a7",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 2: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac440b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Visualize churn distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='churn', data=df)\n",
    "plt.title('Churn Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Feature Correlations')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18855cf9",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 3: Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff8ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = LabelEncoder()\n",
    "df['gender'] = encoder.fit_transform(df['gender'])\n",
    "df['churn'] = encoder.fit_transform(df['churn'])\n",
    "\n",
    "# Feature Selection\n",
    "X = df.drop(columns=['customer_id', 'churn'])\n",
    "y = df['churn']\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd22e81",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 4: Build Churn Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0702a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train Logistic Regression Model\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Train Random Forest Model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef0074",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 5: Evaluate & Compare Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12876a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluate models\n",
    "models = {'Logistic Regression': log_reg, 'Random Forest': rf}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\n",
    "\", classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a5c08",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 6: NLP for Customer Feedback Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd72bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install nltk textblob\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Sample feedback column\n",
    "df['feedback'] = df['feedback'].fillna('')  # Handle missing feedback\n",
    "\n",
    "# Sentiment Analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['sentiment_score'] = df['feedback'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# Display sentiment distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(df['sentiment_score'], bins=20, kde=True)\n",
    "plt.title('Sentiment Score Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Sample insights\n",
    "df[['feedback', 'sentiment_score']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4001c185",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 7: Generative AI Chatbot for Retention Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install transformers\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a generative model for chatbot responses\n",
    "chatbot = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "def chatbot_response(user_query):\n",
    "    response = chatbot(user_query, max_length=50, num_return_sequences=1)\n",
    "    return response[0]['generated_text']\n",
    "\n",
    "# Example chat\n",
    "query = \"My debit card is not working.\"\n",
    "print(\"User:\", query)\n",
    "print(\"Chatbot:\", chatbot_response(query))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ecb60a",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Step 8: Deployment & API Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a14719",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install fastapi uvicorn\n",
    "\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/predict_churn/\")\n",
    "def predict_churn(customer_id: int):\n",
    "    customer_data = df[df['customer_id'] == customer_id].drop(columns=['customer_id', 'churn'])\n",
    "    customer_data_scaled = scaler.transform(customer_data)\n",
    "    prediction = rf.predict(customer_data_scaled)[0]\n",
    "    return {\"Customer ID\": customer_id, \"Churn Prediction\": bool(prediction)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
